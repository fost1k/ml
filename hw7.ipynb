{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Домашнее задание\n",
    "1. взять любой набор данных для бинарной классификации (можно скачать один из модельных с https://archive.ics.uci.edu/ml/datasets.php)\n",
    "2. сделать feature engineering\n",
    "3. обучить любой классификатор (какой вам нравится)\n",
    "4. далее разделить ваш набор данных на два множества: P (positives) и U (unlabeled). Причем брать нужно не все положительные (класс 1) примеры, а только лишь часть\n",
    "5. применить random negative sampling для построения классификатора в новых условиях\n",
    "6. сравнить качество с решением из пункта 4 (построить отчет - таблицу метрик)\n",
    "7. поэкспериментировать с долей P на шаге 5 (как будет меняться качество модели при уменьшении/увеличении размера P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import catboost as catb\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weatherAUS.csv', sep=',')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Посомтрим на пропуски\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Посмотрим на типы данных в датасете\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'RainTomorrow'\n",
    "base_feature_names = df.columns.drop([target_name]).tolist()\n",
    "cat_feature_names = df.select_dtypes(include='object').columns.drop([target_name]).tolist()\n",
    "num_feature_names = df.columns.drop([target_name] + cat_feature_names).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainTomorrow'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразуем target\n",
    "\n",
    "df.loc[df['RainTomorrow'] == 'No', 'RainTomorrow'] = 0\n",
    "df.loc[df['RainTomorrow'] == 'Yes', 'RainTomorrow'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainTomorrow'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainTomorrow'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выкинем  значения, где наш таргет неопределен\n",
    "\n",
    "df = df[df['RainTomorrow'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поменяем тип данных\n",
    "\n",
    "df = df.astype({\"RainTomorrow\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на соотношение классов \n",
    "\n",
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "ax = sns.countplot(x=\"RainTomorrow\", data=df, palette=\"Set1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Посмотрим на соотношение классов в численном выражении\n",
    "\n",
    "df['RainTomorrow'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корреляция целевой переменной с базовыми признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = df[base_feature_names + [target_name]].corr().iloc[:-1, -1].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.barplot(x=corr_with_target.values, y=corr_with_target.index)\n",
    "\n",
    "plt.title('Корреляция целевой переменной с базовыми признаками')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица корреляций признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15))\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "\n",
    "corr_matrix = df[base_feature_names].corr()\n",
    "corr_matrix = np.round(corr_matrix, 2)\n",
    "corr_matrix[np.abs(corr_matrix) < 0.2] = 0\n",
    "\n",
    "sns.heatmap(corr_matrix, annot=True, linewidths=.5, cmap='GnBu')\n",
    "\n",
    "plt.title('Матрица корреляций признаков')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_feature_names].hist(figsize=(20, 20), bins=80, grid=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посомтрим на сводную статистику в числовыхпеременных\n",
    "\n",
    "print(round(df[num_feature_names].describe()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обработаем пропущенные значения числовых признаков в X_train\n",
    "\n",
    "for col in df[num_feature_names]:\n",
    "    col_median = df[col].median()\n",
    "    df[col].fillna(col_median, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим наличие пропусков еще раз X_train\n",
    "\n",
    "df[num_feature_names].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка количества элементов в категориальных переменных\n",
    "\n",
    "for var in cat_feature_names:\n",
    "    \n",
    "    print(var, ' содержит ', len(df[var].unique()), ' labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что есть переменная Date, которую нужно предварительно обработать. Предварительную обработку сделаем позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведем фичу Date к нормальному формату даты \n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлечь год, месяц и день из числа\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим столбец Date\n",
    "\n",
    "df.drop('Date', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновим наши список наших категориальных фичей, чтобы в нем не было даты, которая была типом \"object\"\n",
    "cat_feature_names = df.select_dtypes(include='object').columns.tolist()\n",
    "cat_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывести процент пропущенных значений в категориальных переменных в X_train\n",
    "\n",
    "df[cat_feature_names].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# присвоим отсутствующим категориальным переменным наиболее частое значение\n",
    "\n",
    "df['WindGustDir'].fillna(df['WindGustDir'].mode()[0], inplace=True)\n",
    "df['WindDir9am'].fillna(df['WindDir9am'].mode()[0], inplace=True)\n",
    "df['WindDir3pm'].fillna(df['WindDir3pm'].mode()[0], inplace=True)\n",
    "df['RainToday'].fillna(df['RainToday'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведем признак RainToday в числовой\n",
    "df.loc[df['RainToday'] == 'No', 'RainToday'] = 0\n",
    "df.loc[df['RainToday'] == 'Yes', 'RainToday'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RainToday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({\"RainToday\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Обновим наши список наших категориальных фичей, чтобы в нем не было RainToday\n",
    "cat_feature_names = df.select_dtypes(include='object').columns.tolist()\n",
    "cat_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#кодируем все категориальные признаки с помощью get_dummies\n",
    "df = pd.get_dummies(df, columns = cat_feature_names, prefix_sep = \"_\", drop_first = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем закодированные категориальные признаки\n",
    "df = df.drop(columns=cat_feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=target_name)\n",
    "y = df[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catb_model = catb.CatBoostClassifier(\n",
    "    random_state=42,  \n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.025,\n",
    "#     cat_features = cat_feature_names\n",
    ")\n",
    "\n",
    "catb_model.fit(X_train, y_train)\n",
    "y_predict = catb_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмоттрим на метрики\n",
    "\n",
    "results = {}\n",
    "\n",
    "def evaluate_results(y_valid, y_predict):\n",
    "\n",
    "    f1 = f1_score(y_valid, y_predict)\n",
    "    roc = roc_auc_score(y_valid, y_predict)\n",
    "    rec = recall_score(y_valid, y_predict, average='binary')\n",
    "    prc = precision_score(y_valid, y_predict, average='binary')\n",
    "    results = {'metric': ['f1_score', 'roc_auc_score', 'recall', 'precision'],\n",
    "               'catboost_model': [f1, roc, rec, prc],\n",
    "              }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_catb_model = evaluate_results(sample_test.iloc[:,-2].values, y_predict)\n",
    "results_catb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pd.DataFrame(evaluate_results(y_valid, y_predict))\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# скопируем наш датасет\n",
    "mod_df = df.copy()\n",
    "\n",
    "#добавим тестовый признак\n",
    "mod_df['class_test'] = 0\n",
    "\n",
    "# беру только RainTomorrow = 1\n",
    "mod_df_P = mod_df.loc[mod_df['RainTomorrow'] == 1]\n",
    "mod_df_N = mod_df.loc[mod_df['RainTomorrow'] == 0]\n",
    "\n",
    "# делю датафрейм 70 на 30 и перемешиваю его \n",
    "mod_df_P_70, mod_df_P_30 = train_test_split(mod_df_P, test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "# беру кусочек 30% и заменяю в нем значения class_test на 1, там где RainTomorrow = 1\n",
    "mod_df_P_30.loc[mod_df_30['RainTomorrow'] == 1, 'class_test'] = 1\n",
    "mod_df_P_30.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df_N.shape, mod_df_P_70.shape, mod_df_P_30.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_df = pd.concat([mod_df_P_30, mod_df_P_70, mod_df_N],axis=0)\n",
    "mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поменяем расстановку столбцов для удобства\n",
    "\n",
    "mod_df = mod_df[[c for c in mod_df if c not in ['RainTomorrow', 'class_test']] \n",
    "       + ['RainTomorrow', 'class_test']]\n",
    "mod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_df = mod_df.sample(frac=1)\n",
    "neg_sample = mod_df[mod_df['class_test']==0][:len(mod_df[mod_df['class_test']==1])]\n",
    "sample_test = mod_df[mod_df['class_test']==0][len(mod_df[mod_df['class_test']==1]):]\n",
    "pos_sample = mod_df[mod_df['class_test']==1]\n",
    "print(neg_sample.shape, pos_sample.shape)\n",
    "sample_train = pd.concat([neg_sample, pos_sample]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catb.CatBoostClassifier(\n",
    "    random_state=42,  \n",
    "    n_estimators=1200, \n",
    "    learning_rate=0.025,\n",
    "#     cat_features = cat_feature_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(sample_train.iloc[:,:-2].values, \n",
    "          sample_train.iloc[:,-2].values)\n",
    "y_predict = model.predict(sample_test.iloc[:,:-2].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмоттрим на метрики\n",
    "\n",
    "results = {}\n",
    "\n",
    "def evaluate_results_rns(y_valid, y_predict):\n",
    "\n",
    "    f1 = f1_score(y_valid, y_predict)\n",
    "    roc = roc_auc_score(y_valid, y_predict)\n",
    "    rec = recall_score(y_valid, y_predict, average='binary')\n",
    "    prc = precision_score(y_valid, y_predict, average='binary')\n",
    "    results = {'metric': ['f1_score', 'roc_auc_score', 'recall', 'precision'],\n",
    "               'rns_model': [f1, roc, rec, prc],\n",
    "              }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rns_model = evaluate_results_rns(sample_test.iloc[:,-2].values, y_predict)\n",
    "models_results['rns_model'] = results_rns_model['rns_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(models_results)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
